{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb43cea-5c78-47d9-ac57-5cdc01749ac1",
   "metadata": {},
   "source": [
    "## Laboratory 2 - Spark RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63874524-a562-4b9c-9050-72c44aeb7862",
   "metadata": {},
   "source": [
    "### 1.0 Problem Specification: Analysis of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75d34b-c678-4acb-ae34-27ba05782dea",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Questions:\n",
    "##### 1.0.1 Can you draw 5 samples from the input RDD? Which command do you use?<br>1.0.2 Now pick the first 5 words in order of frequency.<br>1.0.3 How many words does the file contain?<br> 1.0.4 Is \"word_frequency.tsv\" a folder or a file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfec3854-080a-4080-a102-6a72c7e31b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath  = \"/data/students/bigdata_internet/lab2/word_frequency.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0613df-c6ed-4a9c-877d-53a8ebb57cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the input file\n",
    "readingsRDD = sc.textFile(inputPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ebf12c-626d-4db4-ab3a-c181860ebaa5",
   "metadata": {},
   "source": [
    "#### Answer of 1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1a0f1c-0e29-483e-bf73-247bf8a3ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw 5 samples\n",
    "samples = readingsRDD.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab074f4f-b79f-4536-aab0-7663fdd334dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steak)\t9\n",
      "clearsave\t1\n",
      "(56g)\t1\n",
      "Chamomiles\t12\n",
      "fleas\"\t2\n"
     ]
    }
   ],
   "source": [
    "# Display the samples\n",
    "for sample in samples:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e2a41-b14d-4629-abb4-fd9d649c59eb",
   "metadata": {},
   "source": [
    "#### Answer of 1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595e0274-0244-4c78-aa9a-149393cf09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data and create (word, frequency) tuples\n",
    "word_frequency_rdd = readingsRDD.map(lambda line: tuple(line.split('\\t'))).map(lambda x: (x[0], int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7740e220-9909-4131-9de0-f3b8c93c9492",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Sort the RDD by frequency in descending order\n",
    "sorted_rdd = word_frequency_rdd.sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8115530f-8060-4206-8554-8a7a2d00f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Take the first 5 words in order of frequency\n",
    "top_words = sorted_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97034728-28c0-4aa3-8e23-60c21fd6d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1630750), ('I', 1448619), ('and', 1237250), ('a', 1164419), ('to', 997979)]\n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca50663-d8f8-4701-adc3-122d09ab4bf4",
   "metadata": {},
   "source": [
    "#### Answer of 1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16478bb7-3a2b-4d01-b65d-24b60de75a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of words\n",
    "total_words = word_frequency_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f01aa23c-5f2c-422b-a8df-2716610705bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 339819\n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "print(\"Total number of words:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48e845-be8a-4ab4-98d3-72f8cc3834bb",
   "metadata": {},
   "source": [
    "#### Answer of 1.0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78519df-3215-4de7-a002-4f7b58879e6e",
   "metadata": {},
   "source": [
    "The name \"word_frequency.tsv\" implies that it is a file rather than a directory, with the \".tsv\" extension indicating its format as tab-separated values (TSV). In HDFS, both files and directories can share the same name but reside in different locations within the file system. To ascertain whether \"word_frequency.tsv\" is a file or a folder in HDFS, Hadoop FileSystem commands can be employed. By executing the provided code, we can confirm it as a file based on the displayed information, encompassing details such as file size and modification time. For a directory, the output would include a list of its contents. The command for verification is as follows:\n",
    "hadoop fs -ls /data/students/bigdata_internet/lab2/word_frequency.tsv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe6fe7-c004-475a-9bcc-180c69c70d42",
   "metadata": {},
   "source": [
    "#### 1.1 Filter words starting with a specified prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52156d-3a2d-4426-952e-576e27f493ec",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "##### 1.1.1 How many lines are left?\n",
    "##### 1.1.2 How frequent is the most frequent word of the selected sample (i.e., the maximum value of `freq` in the lines obtained by applying the filter)?\n",
    "##### 1.1.3 Report the code of 3 different ways to solve the task number 1.1.2 (we only want the frequency, i.e., a number and not a tuple/list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0f72d-799f-4ba0-b1de-6c7d5ef75104",
   "metadata": {},
   "source": [
    "#### Answer of 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4de4819b-dd8b-4a9b-96d2-f013dfb84859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter lines containing words starting with the prefix 'ho'\n",
    "filtered_rdd = readingsRDD.filter(lambda line: line.split('\\t')[0].startswith('ho'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94ce49a8-8027-40db-aebb-a579b26fc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of remaining lines\n",
    "remaining_lines = filtered_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1fdafd-8982-42bc-b31a-054ed1f8adbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines after filtering: 1519\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of lines after filtering:\", remaining_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de6572-448b-406a-b1e5-53a3928437ce",
   "metadata": {},
   "source": [
    "#### Answer of 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4846b46-76e9-4944-917a-7438bb07e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract (word, frequency) tuples\n",
    "filtered_word_frequency_rdd = filtered_rdd.map(lambda line: tuple(line.split('\\t'))).map(lambda x: (x[0], int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac02029a-155a-44ac-a807-7d8b840c6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum frequency\n",
    "max_frequency = filtered_word_frequency_rdd.map(lambda x: x[1]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701d3175-bd45-455e-be81-d0066e0c9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of the most frequent word: 36264\n"
     ]
    }
   ],
   "source": [
    "# Display the result\n",
    "print(\"Frequency of the most frequent word:\", max_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330ecb8f-a002-4cbc-a37a-8b6d4e465a4e",
   "metadata": {},
   "source": [
    "#### Answer of 1.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830460d-0bab-4203-87dc-43c56775f844",
   "metadata": {},
   "source": [
    "##### Approach 1: Using reduce action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec989ed8-8d0d-4903-b884-5c52cb8fc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter lines containing words starting with the prefix 'ho'\n",
    "filtered_rdd = rdd.filter(lambda line: line.split('\\t')[0].startswith('ho'))\n",
    "\n",
    "# Extract (word, frequency) tuples\n",
    "filtered_word_frequency_rdd = filtered_rdd.map(lambda line: tuple(line.split('\\t'))).map(lambda x: (x[0], int(x[1])))\n",
    "\n",
    "# Find the maximum frequency using reduce\n",
    "max_frequency = filtered_word_frequency_rdd.map(lambda x: x[1]).reduce(lambda x, y: max(x, y))\n",
    "\n",
    "# Display the result\n",
    "print(\"Frequency of the most frequent word:\", max_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f34a9c-e956-49bb-ad60-b7e430d586e4",
   "metadata": {},
   "source": [
    "##### Approach 2: Using \"sortBy\" and \"first\" actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37fa28-25a8-462a-b715-e53419647612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter lines containing words starting with the prefix 'ho'\n",
    "filtered_rdd = rdd.filter(lambda line: line.split('\\t')[0].startswith('ho'))\n",
    "\n",
    "# Extract (word, frequency) tuples\n",
    "filtered_word_frequency_rdd = filtered_rdd.map(lambda line: tuple(line.split('\\t'))).map(lambda x: (x[0], int(x[1])))\n",
    "\n",
    "# Find the maximum frequency using sortBy and first\n",
    "max_frequency = filtered_word_frequency_rdd.sortBy(lambda x: x[1], ascending=False).first()[1]\n",
    "\n",
    "# Display the result\n",
    "print(\"Frequency of the most frequent word:\", max_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047da3a-0f9e-44de-bad3-4f07c6869933",
   "metadata": {},
   "source": [
    "##### Approach 3: Using \"max\" action with key function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aaf89f-959d-4ddd-9358-0ea9839ea31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter lines containing words starting with the prefix 'ho'\n",
    "filtered_rdd = rdd.filter(lambda line: line.split('\\t')[0].startswith('ho'))\n",
    "\n",
    "# Extract (word, frequency) tuples\n",
    "filtered_word_frequency_rdd = filtered_rdd.map(lambda line: tuple(line.split('\\t'))).map(lambda x: (x[0], int(x[1])))\n",
    "\n",
    "# Find the maximum frequency using max with key function\n",
    "max_frequency = filtered_word_frequency_rdd.max(key=lambda x: x[1])[1]\n",
    "\n",
    "# Display the result\n",
    "print(\"Frequency of the most frequent word:\", max_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cb676-a394-405d-9f9b-3d664f215c03",
   "metadata": {},
   "source": [
    "#### 1.2 Filter most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e6ff7da-a77d-41bd-9ab7-3a93805861a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1630750)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the maximum frequency\n",
    "max_frequency = word_frequency_rdd.map(lambda x: x[1]).max()\n",
    "\n",
    "# Select lines with frequency greater than 70% of max_frequency\n",
    "selected_lines = word_frequency_rdd.filter(lambda x: x[1] > 0.7 * max_frequency)\n",
    "\n",
    "\n",
    "# Select lines with the most frequent words\n",
    "most_frequent_lines = selected_lines.filter(lambda x: x[1] == max_frequency)\n",
    "\n",
    "# Display the result\n",
    "most_frequent_lines.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c6243-bf91-47a6-8054-68df151016c0",
   "metadata": {},
   "source": [
    "#### 1.3 Count the remaining words and save the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa608a6f-3da2-49d1-b099-9145acfebd17",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "##### 1.3.1 Count the number of selected lines and print this number on the standard output.\n",
    "##### 1.3.2 Save the selected words (without frequency) in an hdfs output folder. Every line should contain a single word and ends with a semicolumn (`;`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ea003-9182-4446-84fa-8f306768c743",
   "metadata": {},
   "source": [
    "#### Answer of 1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8105b77-6543-42f8-a3a4-c61d592dd8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected lines: 4\n"
     ]
    }
   ],
   "source": [
    "# Count the number of selected lines\n",
    "num_selected_lines = selected_lines.count()\n",
    "\n",
    "# Print the number of selected lines\n",
    "print(\"Number of selected lines:\", num_selected_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b8315-60c8-49eb-a12a-edece00bbfa0",
   "metadata": {},
   "source": [
    "#### Answer of 1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "536a9fec-666d-40dd-b3e9-3605ddfe4c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I;', 'the;', 'and;', 'a;']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract words from selected lines\n",
    "selected_words = selected_lines.map(lambda x: x[0] + ';')\n",
    "selected_words.collect()\n",
    "\n",
    "# Save the selected words to an HDFS output folder\n",
    "#output_path = \"https://jupyter.polito.it/user/s302866/lab/tree/lab2output.txt\"\n",
    "#selected_words.saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da527ae7-c064-4c55-a16c-4f44568c37f6",
   "metadata": {},
   "source": [
    "### 2.0 Run the application in different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e1ab5-f489-4576-b01b-bdf86e9f22af",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "##### 2.1 Run your script locally and in the cluster (--master option). How much time do the two modes require to run? Is there a difference? Can you give a plausible explanation?\n",
    "##### 2.2 In this application, would caching an RDD increase the performance? If yes, which RDD would you cache?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d495bf-8a0d-4cc6-bf72-b08eaaced7d3",
   "metadata": {},
   "source": [
    "#### Answer of 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0feccdf-7af3-4a69-9394-68f3924c19de",
   "metadata": {},
   "source": [
    "After running the !spark-submit --master local --deploy-mode client 'SampleLab02.py'\n",
    ",it took 4.714531421661377 seconds to run\n",
    "\n",
    "ARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/CDH-6.2.1-1.cdh6.2.1.p0.1425774/lib/spark) overrides detected (/opt/cloudera/parcels/CDH/lib/spark).\n",
    "WARNING: Running spark-class from user-defined location.\n",
    "22/12/20 00:04:20 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
    "22/12/20 00:04:20 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
    "Program took 4.714531421661377  seconds to run                                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d8a35-737e-4967-989b-5bdb7067bfc4",
   "metadata": {},
   "source": [
    "#### Answer of 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a1337-f4c0-4c6e-a70a-84181fea086a",
   "metadata": {},
   "source": [
    "Caching an RDD can improve performance when the RDD is reused multiple times, particularly in iterative or multi-stage Spark applications. Cache RDDs that are frequently accessed to avoid recomputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e23c8-6ca6-4c59-b015-652d9e89ee4c",
   "metadata": {},
   "source": [
    "### 3.0 Bonus Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca813cfd-6165-44c3-9829-de043f764d49",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "##### 3.1 How many words (with repetitions) does it contain? Consider a word all the characters between spaces (elements found with `split()` method)\n",
    "##### 3.2 Report the code to obtain the word frequency file starting from the original file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1b54ed-f9bd-45d1-9633-bb340d3afd8b",
   "metadata": {},
   "source": [
    "#### Answer of 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17544db4-fb94-4fda-a18c-60c30b0824fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words (with repetitions): 45444841\n"
     ]
    }
   ],
   "source": [
    "# Load the RDD from HDFS\n",
    "input_path = \"/data/students/bigdata_internet/lab2/finefoods_text.txt\"\n",
    "readingsRDD = sc.textFile(input_path)\n",
    "\n",
    "# Split lines into words and flatten the result\n",
    "words_rdd = readingsRDD.flatMap(lambda line: line.split())\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counts = words_rdd.countByValue()\n",
    "\n",
    "# Count the total number of words (with repetitions)\n",
    "total_words = sum(word_counts.values())\n",
    "\n",
    "# Display the result\n",
    "print(\"Total number of words (with repetitions):\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49977b5-3fae-47e8-829c-89fa70175214",
   "metadata": {},
   "source": [
    "#### Answer of 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54514d47-8814-4c80-8e59-46d06b845204",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"resultLab03/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "641c1595-be8d-4c44-a664-51d4c7a6df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/20 16:18:02 WARN scheduler.TaskSetManager: Stage 7 contains a task of very large size (889 KB). The maximum recommended task size is 100 KB.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text: split lines into words, convert to lowercase\n",
    "words_rdd = readingsRDD.flatMap(lambda line: line.split()).map(lambda word: word.lower())\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counts = words_rdd.countByValue()\n",
    "\n",
    "# Save the word frequencies to an output file\n",
    "#output_path = \"/data/students/bigdata_internet/lab2/word_frequency_original.tsv\"\n",
    "word_counts_rdd = sc.parallelize(word_counts.items()).map(lambda x: f\"{x[0]}\\t{x[1]}\")\n",
    "word_counts_rdd.saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f11db-2c68-4575-8800-c8a10519b073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
